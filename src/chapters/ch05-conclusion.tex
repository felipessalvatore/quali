\chapter{Conclusion}
\label{ch05:conclusion}

The results so far may seen grim, but they show also a positive side: \textit{the Entailment-QA tasks are not a set of trivial tasks that can be completely solved by the current models}. These results indicated that it is worthwhile to explore this set of task with more detail, either by improving the training using the current models or by exploring new kinds of models. One thing should be clear, we are not concern in obtaining high accuracy on these tasks only (just as a comparison, in \cite{S14-2055} is reported an accuracy of $87\%$ on the SICK dataset by using feature engineering techniques). The main idea is to use an end-to-end QA model to obtain good results in the Entailment-QA task without compromising the accuracy on other well established QA tasks.  

Future work will explore two branches: on the one hand, we need to finish the Entailment-QA corpus to have a fine grain analysis of the result that we are seeing on the SICK corpus; on the other hand, we need to explore the different extensions for all mentioned models \cite{MaCKZRSG17, Serban:2016a} before inferring any kind of limitation of the current set of QA models.